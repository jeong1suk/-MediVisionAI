{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e2363bc",
   "metadata": {},
   "source": [
    "# 한정된 데이터로 Transfer learning 적용해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e603e6",
   "metadata": {},
   "source": [
    "# 1. CT이미지 데이터셋 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c290d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5352efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22606e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./DATASET/Segmentation/\"\n",
    "data_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e394452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>MaskId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430_0.jpg</td>\n",
       "      <td>ID00007637202177411956430_mask_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430_1.jpg</td>\n",
       "      <td>ID00007637202177411956430_mask_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430_2.jpg</td>\n",
       "      <td>ID00007637202177411956430_mask_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430_3.jpg</td>\n",
       "      <td>ID00007637202177411956430_mask_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430_4.jpg</td>\n",
       "      <td>ID00007637202177411956430_mask_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16703</th>\n",
       "      <td>ID00426637202313170790466_403.jpg</td>\n",
       "      <td>ID00426637202313170790466_mask_403.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16704</th>\n",
       "      <td>ID00426637202313170790466_404.jpg</td>\n",
       "      <td>ID00426637202313170790466_mask_404.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16705</th>\n",
       "      <td>ID00426637202313170790466_405.jpg</td>\n",
       "      <td>ID00426637202313170790466_mask_405.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16706</th>\n",
       "      <td>ID00426637202313170790466_406.jpg</td>\n",
       "      <td>ID00426637202313170790466_mask_406.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16707</th>\n",
       "      <td>ID00426637202313170790466_407.jpg</td>\n",
       "      <td>ID00426637202313170790466_mask_407.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16708 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ImageId  \\\n",
       "0        ID00007637202177411956430_0.jpg   \n",
       "1        ID00007637202177411956430_1.jpg   \n",
       "2        ID00007637202177411956430_2.jpg   \n",
       "3        ID00007637202177411956430_3.jpg   \n",
       "4        ID00007637202177411956430_4.jpg   \n",
       "...                                  ...   \n",
       "16703  ID00426637202313170790466_403.jpg   \n",
       "16704  ID00426637202313170790466_404.jpg   \n",
       "16705  ID00426637202313170790466_405.jpg   \n",
       "16706  ID00426637202313170790466_406.jpg   \n",
       "16707  ID00426637202313170790466_407.jpg   \n",
       "\n",
       "                                       MaskId  \n",
       "0        ID00007637202177411956430_mask_0.jpg  \n",
       "1        ID00007637202177411956430_mask_1.jpg  \n",
       "2        ID00007637202177411956430_mask_2.jpg  \n",
       "3        ID00007637202177411956430_mask_3.jpg  \n",
       "4        ID00007637202177411956430_mask_4.jpg  \n",
       "...                                       ...  \n",
       "16703  ID00426637202313170790466_mask_403.jpg  \n",
       "16704  ID00426637202313170790466_mask_404.jpg  \n",
       "16705  ID00426637202313170790466_mask_405.jpg  \n",
       "16706  ID00426637202313170790466_mask_406.jpg  \n",
       "16707  ID00426637202313170790466_mask_407.jpg  \n",
       "\n",
       "[16708 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c144057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_client_id(x):\n",
    "    return x.split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bcb25f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>MaskId</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430_0.jpg</td>\n",
       "      <td>ID00007637202177411956430_mask_0.jpg</td>\n",
       "      <td>ID00007637202177411956430_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430_1.jpg</td>\n",
       "      <td>ID00007637202177411956430_mask_1.jpg</td>\n",
       "      <td>ID00007637202177411956430_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430_2.jpg</td>\n",
       "      <td>ID00007637202177411956430_mask_2.jpg</td>\n",
       "      <td>ID00007637202177411956430_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430_3.jpg</td>\n",
       "      <td>ID00007637202177411956430_mask_3.jpg</td>\n",
       "      <td>ID00007637202177411956430_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430_4.jpg</td>\n",
       "      <td>ID00007637202177411956430_mask_4.jpg</td>\n",
       "      <td>ID00007637202177411956430_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16703</th>\n",
       "      <td>ID00426637202313170790466_403.jpg</td>\n",
       "      <td>ID00426637202313170790466_mask_403.jpg</td>\n",
       "      <td>ID00426637202313170790466_403.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16704</th>\n",
       "      <td>ID00426637202313170790466_404.jpg</td>\n",
       "      <td>ID00426637202313170790466_mask_404.jpg</td>\n",
       "      <td>ID00426637202313170790466_404.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16705</th>\n",
       "      <td>ID00426637202313170790466_405.jpg</td>\n",
       "      <td>ID00426637202313170790466_mask_405.jpg</td>\n",
       "      <td>ID00426637202313170790466_405.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16706</th>\n",
       "      <td>ID00426637202313170790466_406.jpg</td>\n",
       "      <td>ID00426637202313170790466_mask_406.jpg</td>\n",
       "      <td>ID00426637202313170790466_406.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16707</th>\n",
       "      <td>ID00426637202313170790466_407.jpg</td>\n",
       "      <td>ID00426637202313170790466_mask_407.jpg</td>\n",
       "      <td>ID00426637202313170790466_407.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16708 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ImageId  \\\n",
       "0        ID00007637202177411956430_0.jpg   \n",
       "1        ID00007637202177411956430_1.jpg   \n",
       "2        ID00007637202177411956430_2.jpg   \n",
       "3        ID00007637202177411956430_3.jpg   \n",
       "4        ID00007637202177411956430_4.jpg   \n",
       "...                                  ...   \n",
       "16703  ID00426637202313170790466_403.jpg   \n",
       "16704  ID00426637202313170790466_404.jpg   \n",
       "16705  ID00426637202313170790466_405.jpg   \n",
       "16706  ID00426637202313170790466_406.jpg   \n",
       "16707  ID00426637202313170790466_407.jpg   \n",
       "\n",
       "                                       MaskId  \\\n",
       "0        ID00007637202177411956430_mask_0.jpg   \n",
       "1        ID00007637202177411956430_mask_1.jpg   \n",
       "2        ID00007637202177411956430_mask_2.jpg   \n",
       "3        ID00007637202177411956430_mask_3.jpg   \n",
       "4        ID00007637202177411956430_mask_4.jpg   \n",
       "...                                       ...   \n",
       "16703  ID00426637202313170790466_mask_403.jpg   \n",
       "16704  ID00426637202313170790466_mask_404.jpg   \n",
       "16705  ID00426637202313170790466_mask_405.jpg   \n",
       "16706  ID00426637202313170790466_mask_406.jpg   \n",
       "16707  ID00426637202313170790466_mask_407.jpg   \n",
       "\n",
       "                                      id  \n",
       "0        ID00007637202177411956430_0.jpg  \n",
       "1        ID00007637202177411956430_1.jpg  \n",
       "2        ID00007637202177411956430_2.jpg  \n",
       "3        ID00007637202177411956430_3.jpg  \n",
       "4        ID00007637202177411956430_4.jpg  \n",
       "...                                  ...  \n",
       "16703  ID00426637202313170790466_403.jpg  \n",
       "16704  ID00426637202313170790466_404.jpg  \n",
       "16705  ID00426637202313170790466_405.jpg  \n",
       "16706  ID00426637202313170790466_406.jpg  \n",
       "16707  ID00426637202313170790466_407.jpg  \n",
       "\n",
       "[16708 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['id'] = data_df.ImageId.apply(lambda x: extract_client_id(x))\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3802c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_data(data_df, index):\n",
    "    client_ids = np.unique(data_df.id.values)\n",
    "    client_id = client_ids[index]\n",
    "    client_data = data_df[data_df.id == client_id]\n",
    "    Image_files = list(client_data['ImageId'])\n",
    "    mask_files = list(client_data['MaskId'])\n",
    "    return client_id, Image_files, mask_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5225e028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ID00009637202177434476278_161.jpg',\n",
       " ['ID00009637202177434476278_161.jpg'],\n",
       " ['ID00009637202177434476278_mask_161.jpg'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 100\n",
    "get_client_data(data_df, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6d35122",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"background\", \"trachea\", \"heart\", \"lung\"]\n",
    "colors = ((0,0,0), (255,0,0), (0,255,0), (0,0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05f7e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 50\n",
    "client_id, image_files , mask_files = get_client_data(data_df, index)\n",
    "\n",
    "canvas = np.zeros(shape=(512, 2*512+50, 3), dtype=np.uint8)\n",
    "for i in range(len(image_files)):\n",
    "    image = cv2.imread(os.path.join(data_dir, \"images\", image_files[i]))\n",
    "    mask = cv2.imread(os.path.join(data_dir, \"masks\", mask_files[i]))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "    mask[mask<240] = 0\n",
    "    mask[mask>=240] = 255\n",
    "    \n",
    "    canvas[:, 0:512, :] = image\n",
    "    canvas[:, 512+50:2*512+50, :] = mask\n",
    "    \n",
    "    cv2.imshow('image', canvas)\n",
    "    key = cv2.waitKey(100)\n",
    "    if key == 27:\n",
    "        break\n",
    "    if key == ord('s'):\n",
    "        cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1621936",
   "metadata": {},
   "source": [
    "# 2. 데이터셋 구축과 연산을 위한 텐서변환 모듈 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7d08951",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47fe150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CT_dataset():\n",
    "    def __init__(self, data_dir, phase, transformer=None):\n",
    "        self.phase = phase\n",
    "        self.images_dir = os.path.join(data_dir, phase, 'images')\n",
    "        self.masks_dir = os.path.join(data_dir, phase, 'masks')\n",
    "        self.image_files = [filename for filename in os.listdir(self.images_dir) if filename.endswith('jpg')]\n",
    "        self.mask_files = [filename for filename in os.listdir(self.masks_dir) if filename.endswith('jpg')]\n",
    "        assert len(self.image_files) == len(self.mask_files)\n",
    "        \n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(os.path.join(self.images_dir, self.image_files[index]))\n",
    "        image = cv2.resize(image, dsize=(IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_LINEAR)\n",
    "        mask = cv2.imread(os.path.join(self.masks_dir, self.mask_files[index]))\n",
    "        mask = cv2.resize(mask, dsize=(IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        mask[mask < 240] = 0\n",
    "        mask[mask >= 240] = 255\n",
    "        mask = mask / 255\n",
    "        \n",
    "        mask_H, mask_W, mask_C = mask.shape\n",
    "        background = np.ones(shape=(mask_H, mask_W))\n",
    "        background[mask[..., 0] != 0] = 0\n",
    "        background[mask[..., 1] != 0] = 0\n",
    "        background[mask[..., 2] != 0] = 0\n",
    "        \n",
    "        mask = np.concatenate([np.expand_dims(background, axis=-1), mask], axis=-1)\n",
    "        \"\"\"\n",
    "        background shape: (H, W) -> shape 확장 (H, W, 1)로\n",
    "        mask shape: (H, W, C)\n",
    "        \n",
    "        new mask shape: (H, W, C+1)\n",
    "        \"\"\"\n",
    "        mask = np.argmax(mask, axis=-1)\n",
    "        \"new mask shape: (H, W, 4) -> new mask shape: (H, W)\"\n",
    "        \n",
    "        if self.transformer:\n",
    "            image = self.transformer(image)\n",
    "            \n",
    "        target = torch.from_numpy(mask).long()\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29e1dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = CT_dataset(data_dir, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "237b41c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((224, 224, 3), torch.Size([224, 224]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, target = dset[0]\n",
    "image.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a0e0531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def build_transformer():\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "213baecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "    for a, b in batch:\n",
    "        images.append(a)\n",
    "        targets.append(b)\n",
    "    images = torch.stack(images, dim=0)\n",
    "    targets = torch.stack(targets, dim=0)\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "293c88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = build_transformer()\n",
    "dset = CT_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f441a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([3, 224, 224])\n",
      "target shape: torch.Size([224, 224])\n"
     ]
    }
   ],
   "source": [
    "image, target = dset[0]\n",
    "print(f\"image shape: {image.shape}\")\n",
    "print(f\"target shape: {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c6688a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c93d7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = DataLoader(dset, batch_size=4, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c1897bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape: torch.Size([4, 3, 224, 224])\n",
      "targets shape: torch.Size([4, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for index, batch in enumerate(dloader):\n",
    "    images = batch[0]\n",
    "    targets = batch[1]\n",
    "    print(f\"images shape: {images.shape}\")\n",
    "    print(f\"targets shape: {targets.shape}\")\n",
    "    \n",
    "    if index == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4fe76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(data_dir, batch_size=4):\n",
    "    transformer = build_transformer()\n",
    "    \n",
    "    dataloaders = {}\n",
    "    train_dataset = CT_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    val_dataset = CT_dataset(data_dir=data_dir, phase=\"val\", transformer=transformer)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbbdc190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape: torch.Size([4, 3, 224, 224])\n",
      "targets shape: torch.Size([4, 224, 224])\n",
      "images shape: torch.Size([4, 3, 224, 224])\n",
      "targets shape: torch.Size([4, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "dataloaders = build_dataloader(data_dir=data_dir)\n",
    "\n",
    "for phase in [\"train\", \"val\"]:\n",
    "    for index, batch in enumerate(dataloaders[phase]):\n",
    "        images = batch[0]\n",
    "        targets = batch[1]\n",
    "        print(f\"images shape: {images.shape}\")\n",
    "        print(f\"targets shape: {targets.shape}\")\n",
    "        \n",
    "        if index == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf8ee8",
   "metadata": {},
   "source": [
    "# 3. VGG16 Backbone을 이용한 U-Net 아키텍쳐 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edde91b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff87f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvLayer(in_channels, out_channels, kernel_size=3, padding=1):\n",
    "    layers = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    \n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4da7237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpConvLayer(in_channels, out_channels):\n",
    "    layers = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2678d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27c474d1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16 = models.vgg16_bn(pretrained=False)\n",
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3af7adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super().__init__()\n",
    "        \n",
    "        backbone = models.vgg16_bn(pretrained=pretrained).features\n",
    "        self.conv_block1 = nn.Sequential(*backbone[:6])\n",
    "        self.conv_block2 = nn.Sequential(*backbone[6:13])\n",
    "        self.conv_block3 = nn.Sequential(*backbone[13:20])\n",
    "        self.conv_block4 = nn.Sequential(*backbone[20:27])\n",
    "        self.conv_block5 = nn.Sequential(*backbone[27:34],\n",
    "                                        ConvLayer(512, 1024, kernel_size=1, padding=0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encode_features = []\n",
    "        out = self.conv_block1(x)\n",
    "        encode_features.append(out)\n",
    "        \n",
    "        out = self.conv_block2(out)\n",
    "        encode_features.append(out)\n",
    "        \n",
    "        out = self.conv_block3(out)\n",
    "        encode_features.append(out)\n",
    "        \n",
    "        out = self.conv_block4(out)\n",
    "        encode_features.append(out)\n",
    "        \n",
    "        out = self.conv_block5(out)\n",
    "        return out, encode_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ded4f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(pretrained=False)\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "out, ftrs = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e630b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 224, 224])\n",
      "torch.Size([1, 128, 112, 112])\n",
      "torch.Size([1, 256, 56, 56])\n",
      "torch.Size([1, 512, 28, 28])\n",
      "torch.Size([1, 1024, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "for ftr in ftrs:\n",
    "    print(ftr.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb7e9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.upconv_layer1 = UpConvLayer(in_channels=1024, out_channels=512)\n",
    "        self.conv_block1 = ConvLayer(in_channels=512+512, out_channels=512)\n",
    "        \n",
    "        self.upconv_layer2 = UpConvLayer(in_channels=512, out_channels=256)\n",
    "        self.conv_block2 = ConvLayer(in_channels=256+256, out_channels=256)\n",
    "        \n",
    "        self.upconv_layer3 = UpConvLayer(in_channels=256, out_channels=128)\n",
    "        self.conv_block3 = ConvLayer(in_channels=128+128, out_channels=128)\n",
    "        \n",
    "        self.upconv_layer4 = UpConvLayer(in_channels=128, out_channels=64)\n",
    "        self.conv_block4 = ConvLayer(in_channels=64+64, out_channels=64)\n",
    "        \n",
    "    def forward(self, x, encoder_features):\n",
    "        out = self.upconv_layer1(x)\n",
    "        out = torch.cat([out, encoder_features[-1]], dim=1)\n",
    "        out = self.conv_block1(out)\n",
    "        \n",
    "        out = self.upconv_layer2(out)\n",
    "        out = torch.cat([out, encoder_features[-2]], dim=1)\n",
    "        out = self.conv_block2(out)\n",
    "        \n",
    "        out = self.upconv_layer3(out)\n",
    "        out = torch.cat([out, encoder_features[-3]], dim=1)\n",
    "        out = self.conv_block3(out)\n",
    "        \n",
    "        out = self.upconv_layer4(out)\n",
    "        out = torch.cat([out, encoder_features[-4]], dim=1)\n",
    "        out = self.conv_block4(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bee0fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(pretrained=False)\n",
    "decoder = Decoder()\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "out, ftrs = encoder(x)\n",
    "out = decoder(out, ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46f8ee0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fef73b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(pretrained)\n",
    "        self.decoder = Decoder()\n",
    "        self.head = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, encode_features = self.encoder(x)\n",
    "        out = self.decoder(out, encode_features)\n",
    "        out = self.head(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "764269bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(num_classes=4, pretrained=False)\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f3d5dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9730808",
   "metadata": {},
   "source": [
    "# 4. Semantic segmentation Loss와 학습코드 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366b758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4292b104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c791b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86a4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5455409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2531199f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4797531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17c161a3",
   "metadata": {},
   "source": [
    "# 5. Weight Initialization 과 Transfer learning 모델 비교하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caa7c9c",
   "metadata": {},
   "source": [
    "## 5-1 He initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f665440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
